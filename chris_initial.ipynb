{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db24bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import prepare \n",
    "import acquire  \n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mergedeep import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21144299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire the URLS for the Repositories to explore\n",
    "\n",
    "headers = acquire.headers\n",
    "endpoint = \"https://api.github.com/search/repositories\"\n",
    "query = \"customer in:name\"\n",
    "sort = \"stars\"\n",
    "per_page = 100\n",
    "order = \"desc\"\n",
    "page = 1\n",
    "\n",
    "##Make the request\n",
    "response = requests.get(f\"{endpoint}?q={query}&sort={sort}&per_page={per_page}&order={order}&page={page}\", headers=headers)\n",
    "payload = response.json()\n",
    "#payload['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 2\n",
    "\n",
    "##Make the request\n",
    "response = requests.get(f\"{endpoint}?q={query}&sort={sort}&per_page={per_page}&order={order}&page={page}\", headers=headers)\n",
    "payload2 = response.json()\n",
    "merge(payload, payload2)\n",
    "payload['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 3\n",
    "\n",
    "##Make the request\n",
    "response = requests.get(f\"{endpoint}?q={query}&sort={sort}&per_page={per_page}&order={order}&page={page}\", headers=headers)\n",
    "payload2 = response.json()\n",
    "merge(payload, payload2)\n",
    "payload['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedfb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the reponse to a data frame\n",
    "urls_df = pd.DataFrame(payload['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the dataframe\n",
    "urls_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of the full_name for the urls. Saved to acquire seperate file as repos and assigned to a variable\n",
    "urls_df.full_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fe6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the scrape github function from the acquire module to acquire the dataframe containing the names of the\n",
    "#repositories and the contents of the readme files\n",
    "df = acquire.scrape_github_data()\n",
    "\n",
    "#convert the data into a dataframe\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c15cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json file generated by compiling the acquire.py file\n",
    "df = pd.read_json('data2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do drop unneeded data first then prep\n",
    "df = prepare.drop_unneeded_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
